\newpage
\chapter{METODE PENELITIAN} \label{Bab III}

\section{Alur Penelitian} \label{III.Alur}
Penelitian ini dilaksanakan melalui serangkaian tahapan sistematis guna memastikan model klasifikasi suara ancaman bahaya yang dikembangkan dapat bekerja optimal pada domain keselamatan penyandang tunarungu.
Diagram alur penelitian ditunjukkan pada Gambar \ref{fig:alur_penelitian}.

\begin{figure}[H]
    \centering
    % Ganti 'gambar/alur_penelitian.png' dengan nama file gambar kamu
    \includegraphics[width=1.0\textwidth]{figure/Flowchart_TA.pdf} 
    \caption{Diagram Alur Penelitian}
    \label{fig:alur_penelitian}
\end{figure}

Penjelasan rinci mengenai tahapan penelitian adalah sebagai berikut:

\begin{enumerate}
    \item \textbf{Identifikasi Domain Penelitian} \\
    Tahap awal dilakukan dengan mencari referensi domain penelitian untuk klasifikasi suara. Berdasarkan pertimbangan ketersediaan dataset dan urgensi model klasifikasi, domain yang dipilih adalah domain keselamatan publik yang difokuskan untuk alat bantu penyandang tunarungu.

    \item \textbf{Studi Literatur} \\
    Dilakukan kajian literatur mendalam untuk menemukan urgensi penelitian, khususnya mengenai kebutuhan teknologi asistif yang mampu mengurangi risiko kecelakaan bagi penyandang tunarungu melalui pengenalan sinyal bahaya. Ini menjadi landasan teoritis bagaimana teknologi klasifikasi suara dapat menjadi solusi yang efektif dalam mengatasi permasalahan tersebut.

    \item \textbf{Identifikasi dan Akuisisi Data} \\
    Akuisisi data dilakukan dengan mengambil dataset sekunder yang sudah terstandarisasi, yaitu UrbanSound8K \cite{salamon2014dataset}. Akuisisi data primer tidak dilakukan demi menghindari \textit{device bias} akibat perekaman dataset dengan perangkat non-standar (seperti smartphone) serta kendala regulasi keamanan pada perekaman kelas \textit{gun\_shot}. Dari dataset tersebut, dilakukan seleksi kelas sinyal bahaya dengan strategi antisipasi terhadap kendala ketidakseimbangan data (\textit{imbalanced data}) yang telah disiapkan sejak awal.    

    \item \textbf{Pemilihan Model \textit{Pre-trained}} \\
    Mengingat keterbatasan data berisiko menyebabkan kegagalan pelatihan \textit{from scratch}, digunakan pendekatan \textit{Transfer Learning} dengan memanfaatkan model \textit{Pre-trained}.
    Tiga varian arsitektur PANNs (\textit{Pre-trained Audio Neural Networks}) \cite{kong2020panns} dipilih untuk mewakili domain input yang berbeda, yaitu \textit{Res1dNet31} (domain waktu), \textit{ResNet38} (domain frekuensi), dan \textit{Wavegram-Logmel-CNN} (\textit{hybrid}). 
    Arsitektur PANNs dipilih karena telah dilatih pada dataset masif (AudioSet) dan memiliki performa yang teruji. \par

    \item \textbf{Studi Dokumentasi Teknis} \\
    Tahap ini mempelajari karakteristik data dan model yang digunakan.
    Fokus utama dalam tahap ini adalah memahami mekanisme pembagian data (fold) pada dataset guna mencegah kebocoran data (\textit{data leakage}) dan mempelajari variasi representasi input pada arsitektur PANNs untuk menentukan skenario komparasi yang tepat.

    \newpage
    
    \item \textbf{\textit{Pre-processing} Data} \\
    Serangkaian proses dilakukan untuk mengubah data mentah menjadi format yang siap latih, meliputi penanganan struktur \textit{fold}, seleksi kelas, dan penyesuaian format audio, serta penerapan teknik augmentasi temporal berupa \textit{random cropping} untuk menstandarisasi durasi input.

    \item \textbf{Penyesuaian Konfigurasi Model} \\
    Dilakukan modifikasi pada arsitektur model agar sesuai dengan tujuan klasifikasi 4 kelas bahaya, serta penerapan strategi untuk menangani ketidakseimbangan data.

    \item \textbf{Eksperimen \textit{Transfer Learning}} \\
    Tahapan ini menjadi tahapan inti di mana model dilatih ulang (\textit{fine-tuning}) untuk mengenali karakteristik suara spesifik. Proses ini mencakup eksperimen \textit{hyperparameter} dan pelatihan ketiga variasi model untuk menemukan konfigurasi parameter pelatihan yang paling optimal.
    Proses ini bersifat iteratif. Apabila performa model belum mencapai target yang diharapkan, maka akan dilakukan penyesuaian ulang pada tahap \textit{pre-processing} data untuk melakukan penyesuaian data dan melakukan pelatihan kembali hingga diperoleh model yang optimal.

    \item \textbf{Evaluasi dan Analisis Hasil} \\
    Performa model hasil \textit{fine-tuning} dievaluasi menggunakan metrik \textit{F1-Score}, nilai \textit{Loss}, dan analisis \textit{Confusion Matrix}.
    Evaluasi ini bertujuan untuk membandingkan dan menganalisis performa antara ketiga model dalam melakukan klasifikasi suara ancaman bahaya.

    \item \textbf{Kesimpulan} \\
    Berdasarkan hasil evaluasi, dilakukan perbandingan komparatif untuk menyimpulkan model mana yang memiliki performa paling unggul dan stabil.
\end{enumerate}

\section{Pengumpulan dan Pra-pemrosesan Data} \label{III.Preprocessing}
Sumber data utama dalam penelitian ini adalah dataset publik \textbf{UrbanSound8K} \cite{salamon2014dataset}.
Dataset ini diunduh dalam format terkompresi (\texttt{.zip}).
Setelah diekstraksi, struktur dataset terdiri dari 10 folder (masing-masing mewakili satu \textit{fold}) beserta satu file metadata (\texttt{.csv}) yang memuat informasi nama file audio, \textit{class ID}, dan \textit{fold} asal. \par

Namun, dataset mentah ini memerlukan serangkaian penyesuaian agar relevan dengan konteks keselamatan penyandang tunarungu. 
Mengingat dataset ini awalnya berisi 10 kelas suara umum di perkotaan yang tersebar dalam 10 \textit{fold}, penelitian ini memfokuskan pada seleksi kelas bahaya spesifik serta menyusun ulang data menjadi 5 fold eksperimen.
Sebagai langkah antisipasi terhadap keterbatasan data setelah seleksi kelas, strategi augmentasi temporal diterapkan untuk memperkaya variasi data latih.
Oleh karena itu, tahap pra-pemrosesan data menjamin integritas data dan mencegah kebocoran informasi (\textit{data leakage}) selama proses pelatihan, sebagaimana dijabarkan pada tahapan berikut.\par

\subsection{Seleksi Kelas (\textit{Class Filtering})}
Tidak seluruh kelas pada dataset UrbanSound8K relevan dengan konteks keselamatan tunarungu. Oleh karena itu, dilakukan penyaringan untuk hanya mengambil 4 kelas prioritas yang merepresentasikan sinyal bahaya, yaitu:
\begin{enumerate}
    \item \textbf{\textit{gun\_shot} (Tembakan)} \newline
    Suara tembakan senjata api merupakan sinyal bahaya dengan tingkat fatalitas yang sangat tinggi. Walaupun kejadiannya jarang terjadi, khususnya di Indonesia, deteksi suara ini menjadi langkah mitigasi risiko yang baik dalam melindungi penyandang tunarungu.
    
    \item \textbf{\textit{siren} (Sirine)} \newline
    Suara sirine menandakan keberadaan kendaraan prioritas (ambulans, pemadam kebakaran, atau patroli polisi) yang sering kali melaju dengan kecepatan tinggi dan memiliki hak prioritas jalan. Dengan deteksi suara tersebut, pengguna dapat mengambil langkah untuk segera menepi dan menghindari jalur lintasan kendaraan tersebut.
    
    \item \textbf{\textit{dog\_bark} (Gonggongan Anjing)} \newline
    Suara anjing yang menggonggong berpotensi menjadi sinyal bahaya, terutama jika anjing tersebut berupa anjing liar yang dapat menyerang secara tiba-tiba. Dengan mendeteksi suara ini, pengguna dapat langsung mengetahui di mana posisi anjing tersebut dan mengambil langkah untuk antisipasi ancaman.
    
    \item \textbf{\textit{car\_horn} (Klakson Mobil)} \newline
    Suara klakson mobil menjadi sinyal penting pada lalu lintas, yang salah satu fungsinya adalah sebagai peringatan dari pengemudi kendaraan tersebut kepada pejalan kaki yang berada di jalur lintasnya. Dengan deteksi ini, pengguna dapat lebih waspada terhadap situasi lalu lintas di sekitarnya.
\end{enumerate}

\subsection{Strategi Penyusunan Ulang Data (\textit{Fold Mapping})}
Dataset UrbanSound8K secara bawaan terbagi ke dalam 10 \textit{fold}.
Untuk efisiensi eksperimen tanpa melanggar aturan independensi data, penelitian ini menyusun ulang 10 \textit{fold} tersebut menjadi 5 \textit{fold} eksperimen baru.
Penyusunan ini dilakukan secara berurutan (misalnya Fold 1 dan 2 menjadi Fold Baru 1) tanpa pengacakan data antar \textit{fold}.
Teknik penyusunan tersebut memastikan data latih dan data uji tidak tercampur pada fold yang sama, sehingga teknik penyusunan ini menghindari adanya kebocoran data (\textit{data leakage}) yang menyebabkan model menjadi \textit{overfitting}.
% Gambar
\begin{figure}[H]
    \centering
    % Ganti 'gambar/alur_penelitian.png' dengan nama file gambar kamu
    \includegraphics[width=1.0\textwidth]{figure/Fold_Map.pdf} 
    \caption{Ilustrasi Strategi Penyusunan Ulang Fold pada Dataset UrbanSound8K}
    \label{fig:strategi_fold_mapping}
\end{figure}

Adapun penyusunan ini didasari oleh dua pertimbangan, yaitu rasio pembagian data yang ideal dan efisiensi sumber daya komputasi. Skema 5-\textit{fold} menghasilkan proporsi 80\% data latih dan 20\% data uji. Proporsi ini memberikan model evaluasi yang lebih representatif terhadap variasi data daripada skema 10-\textit{fold} bawaan yang menyisakan 10\% data uji. Selain memberikan porsi data yang ideal, skema tersebut berdampak mengurangi waktu komputasi pelatihan model tanpa mengurangi validitas pengujian.

Dikarenakan skema baru tersebut, maka mekanisme validasi yang digunakan selanjutnya pada model adalah \textit{5-fold cross validation}. Pada iterasi setiap pengujiannya, satu \textit{fold} dialokasikan sebagai data uji secara bergantian dan empat \textit{fold} sisanya akan digunakan sebagai data latih model. Mekanisme rotasi ini diterapkan agar model selalu diuji dengan data yang berbeda dari yang sudah pernah dipelajari saat proses latih, sehingga hasil evaluasi mencerminkan kemampuan generalisasi yang sebenarnya.

\subsection{Standarisasi Format Audio}
Sebelum data audio dapat diproses oleh model, diperlukan standarisasi format pada data tersebut mengingat data mentah memiliki format yang berbeda-beda.
Ketidaksesuaian format input dapat menyebabkan kegagalan pada proses ekstraksi fitur, bahkan pelatihan model.
Oleh karena itu, standarisasi format menjadi langkah penting untuk memastikan bahwa semua data audio memiliki format yang konsisten dan sesuai dengan kebutuhan model, di mana langkah-langkah tersebut mencakup :
\begin{enumerate}
    \item \textbf{Konversi \textit{Channel} Audio (\textit{Down-mixing})} \newline
    Langkah ini diterapkan karena terdapat beberapa data audio dengan format stereo (dua \textit{channel}). Semua data audio dikonversi menjadi format mono (satu \textit{channel}) untuk menyederhanakan representasi suara dan mengurangi kompleksitas komputasi.

    \item \textbf{Penyesuaian Sampling Rate (\textit{Resampling})} \newline
    Setelah audio diubah menjadi format mono, dilakukan penyesuaian sampling rate (\textit{resampling}). Sampling rate pada dataset UrbanSound8K bervariatif, sehingga sampling rate pada data diubah menjadi 32.000 Hz agar sesuai dengan standar input pada model PANNs.
\end{enumerate}

\subsection{Augmentasi Temporal (\textit{Random Cropping})}
Seleksi kelas bahaya yang telah dilakukan menghasilkan jumlah data yang relatif sedikit pada kelas yang terpilih, yang berpotensi membuat model kekurangan data untuk latih dan uji. 
Oleh karena itu, teknik augmentasi hadir sebagai solusi untuk memperkaya variasi data tanpa perlu menambah jumlah sampel dengan dataset lain.
Teknik ini juga mempersingkat waktu dan sumber daya komputasi dikarenakan model hanya mempelajari sebagian fitur penting dari seluruh bagian fitur pada data aslinya.\par

Sebelum melakukan proses augmentasi, durasi audio akan diperiksa terlebih dahulu apakah sesuai dengan standar yang telah ditetapkan, yaitu 5 detik. 
Durasi 5 detik ini dipilih karena dataset UrbanSound8K memiliki data audio yang berdurasi rata-rata 4 detik, sehingga 5 detik merupakan durasi yang cukup aman untuk dijadikan standar dalam penelitian ini.
Jika audio asli berdurasi kurang dari 5 detik, maka audio akan ditambahkan \textit{padding} hingga durasinya mencapai 5 detik.
Jika audio asli berdurasi lebih dari 5 detik, maka audio akan dipotong hingga berdurasi 5 detik.
Setelah standarisasi durasi selesai, maka data siap untuk diproses menggunakan teknik augmentasi. \par

Teknik augmentasi yang diterapkan adalah \textit{Random Cropping}, yaitu pemotongan acak pada segmen audio sepanjang durasi tertentu.
Pada setiap \textit{epoch} pelatihan, segmen 1 detik akan diambil secara acak dari durasi 5 detik tersebut. Ini memberikan variasi temporal pada model untuk belajar mengenali karakteristik suara yang berbeda dari berbagai posisi dalam rekaman asli pada setiap \textit{epoch}.
Teknik \textit{Random Cropping} ini tidak diterapkan pada data uji dikarenakan berpotensi mengubah distribusi data uji, sehingga model tidak dapat mencapai nilai evaluasi secara maksimal. 
Strategi ini memastikan bahwa data uji memiliki dimensi yang konsisten, sehingga performa model dapat dievaluasi secara stabil dan tolak ukur pengujian dapat direproduksi dengan akurat.\par

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figure/Random_Crop.pdf} 
    \caption{Ilustrasi Teknik \textit{Random Cropping} Pada Setiap \textit{Epoch}}
    \label{fig:random_cropping}
\end{figure}

\section{Konfigurasi Model} \label{sec:konfigurasi_model}
% Kasih paragraf pembuka
Model yang digunakan dalam penelitian ini adalah model PANNs \cite{kong2020panns} dengan 3 arsitektur berbeda, yaitu \textit{Res1dNet31}, \textit{ResNet38}, dan \textit{Wavegram-Logmel-CNN}.
Ketiga arsitektur ini telah terbukti memiliki performa yang baik pada tugas klasifikasi audio berdasarkan masing-masing representasi inputnya. 
Namun, agar model dapat berfungsi optimal sesuai dengan konteks klasifikasi 4 kelas bahaya pada dataset UrbanSound8K, diperlukan beberapa penyesuaian konfigurasi model, yaitu sebagai berikut. \par

\subsection{Modifikasi Arsitektur PANNs}
Modifikasi beberapa komponen pada arsitektur PANNs diperlukan pada lapisan keluaran (\textit{output layer}). 
Langkah ini dilakukan mengingat jumlah kelas pada \textit{output layer} yang belum sesuai dengan target kelas suara yang ditentukan dan penyesuaian jenis output klasifikasi PANNs yang awalnya \textit{multi-label}.
Oleh karena itu, dilakukan dua penyesuaian utama:
\begin{enumerate}
    \item \textbf{Penyesuaian Jumlah Neuron pada Lapisan Akhir} \newline
    Jumlah \textit{neuron} pada lapisan akhir disesuaikan dari 527 \textit{node} menjadi 4 \textit{node} (sesuai jumlah kelas pilihan).
    \item \textbf{Penyesuaian Fungsi Aktivasi pada Lapisan Akhir} \newline
    Pada model asli PANNs, lapisan akhir menggunakan fungsi aktivasi \textit{sigmoid} yang mengeluarkan output berupa probabilitas tiap kelasnya sendiri (cocok untuk \textit{multi-label}).
    Namun, klasifikasi model yang ditentukan pada penelitian ini adalah klasifikasi \textit{Single-Label}, sehingga terjadi modifikasi pada lapisan akhir menjadi lapisan \textit{Linear} yang mengeluarkan angka mentah (\textit{logits}).
    Nilai \textit{logits} ini nantinya akan dikonversi menjadi distribusi probabilitas tunggal oleh fungsi kerugian (\textit{Loss Function}) selama fase pelatihan.
    Dengan perubahan ini, model akan memilih satu kelas pemenang dengan probabilitas tertinggi daripada kelas lainnya. \par
\end{enumerate}

\subsection{Strategi \textit{Freeze Base}}
Mengingat penelitian ini menggunakan metode \textit{Transfer Learning}, lapisan dasar fitur (\textit{base model}) pada model PANNs dibekukan agar model tidak menghapus ingatan fitur dasar yang telah dipelajari dari dataset besar sebelumnya (AudioSet) \cite{gemmeke2017audioset}. 
Strategi ini memastikan model memiliki inisialisasi bobot yang baik dan hanya perlu mempelajari pola baru yang spesifik pada dataset target. \par

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figure/Transfer_Learning.pdf} 
    \caption{Ilustrasi \textit{Transfer Learning} (\textit{Freeze} vs \textit{Trainable Base})}
    \label{fig:transfer_learning}
\end{figure}

\subsection{Parameter Konfigurasi Input}
Selain melakukan modifikasi arsitektur, konfigurasi parameter input juga disesuaikan dengan standar yang ditetapkan pada PANNs untuk menjamin kompabilitas dimensi fitur antara data input dengan bobot \textit{pre-trained}, sehingga ekstraksi fitur dapat berjalan optimal tanpa adanya kesalahan dimensi. Rincian konfigurasi tersebut meliputi:

\begin{table}[H]
    \centering
    \caption{Konfigurasi Parameter Input Audio Model PANNs}
    \label{tab:panns_config}
    \small % Opsional: Mengecilkan font tabel sedikit agar terlihat lebih manis
    % Format kolom: 
    % |l| : Kolom 1 rata kiri (lebar sesuai isi)
    % |c| : Kolom 2 rata tengah (lebar sesuai isi)
    % |X| : Kolom 3 fleksibel (mengisi sisa ruang & wrap text)
    \begin{tabularx}{\textwidth}{|l|c|X|} 
        \hline
        \textbf{Parameter} & \textbf{Nilai} & \textbf{Keterangan} \\ \hline
        Sampling Rate & 32.000 Hz & Frekuensi pencuplikan sinyal audio \\ \hline
        Window Size & 1024 & Ukuran jendela FFT (\textit{Fast Fourier Transform}) \\ \hline
        Hop Size & 320 & Jarak pergeseran antar jendela waktu \\ \hline
        Mel-bins & 64 & Jumlah filter bank pada skala Mel (dimensi fitur vertikal) \\ \hline
        F-min & 50 Hz & Batas frekuensi minimum \\ \hline
        F-max & 14.000 Hz & Batas frekuensi maksimum \\ \hline
    \end{tabularx}
\end{table}

Penggunaan \textit{sampling rate} 32 kHz dipilih merujuk pada spesifikasi standar PANNs \cite{kong2020panns}. Angka ini juga telah memenuhi kriteria Teorema Nyquist untuk menangkap frekuensi hingga 16 kHz. Rentang ini dinilai efisien karena sebagian besar energi spektral pada suara bahaya (seperti sirine, klakson, dan tembakan) berada pada rentang 50 Hz hingga 14.000 Hz, sehingga parameter ini dapat mempertahankan informasi vital sekaligus mereduksi beban komputasi dibandingkan standar audio 44.1 kHz.

\section{Eksperimen \textit{Transfer Learning}} \label{sec:eksperimen}
Setelah model dikonfigurasi sesuai kebutuhan penelitian, tahap selanjutnya adalah melakukan eksperimen \textit{Transfer Learning} dengan arsitektur PANNs.
Tahapan ini melibatkan konfigurasi hyperparameter pelatihan secara eksperimental dan penerapan beberapa strategi pelatihan yang bertujuan untuk mendapatkan hasil evaluasi yang optimal.
Beberapa strategi teknis yang diterapkan mencakup pengondisian lingkungan implementasi, penerapan standar reproduksibilitas, penanganan ketidakseimbangan data, serta mekanisme kontrol pelatihan untuk memastikan model mempelajari data dengan baik dan menghindari \textit{overfitting}.
Penggunaan WandB sebagai alat pemantauan dan pencatatan eksperimen pelatihan model secara \textit{real-time} termasuk ke dalam strategi untuk memastikan transparansi dan menjaga validitas dalam merekam hasil eksperimen.
Rincian beberapa langkah strategi teknis tersebut dijabarkan sebagai berikut.

\subsection{Lingkungan Implementasi dan Reproduksibilitas}
Seluruh rangkaian eksperimen pelatihan dijalankan pada satu perangkat komputasi terdedikasi guna menjaga konsistensi performa dan waktu komputasi.
Mengingat perangkat keras memiliki dampak signifikan terhadap efisiensi proses \textit{fine-tuning} model, rincian spesifikasi perangkat keras (\textit{hardware}) yang digunakan dijabarkan pada Tabel \ref{tab:hardware_spec}.

\begin{table}[H]
    \centering
    \caption{Spesifikasi Perangkat Keras untuk Pelatihan}
    \label{tab:hardware_spec}
    \small % Opsional: Mengecilkan font tabel sedikit agar terlihat lebih manis
    % Format kolom: 
    % |l| : Kolom 1 rata kiri (lebar sesuai isi)
    % |c| : Kolom 2 rata tengah (lebar sesuai isi)
    % |X| : Kolom 3 fleksibel (mengisi sisa ruang & wrap text)
    \begin{tabularx}{\textwidth}{|l|p{3.8cm}|X|} 
        \hline
        \textbf{Komponen} & \textbf{Spesifikasi} & \textbf{Keterangan} \\ \hline
        Processor (CPU) & Intel Core i7-7700HQ & Bertanggung jawab atas \textit{pre-processing} data, augmentasi dan manajemen \textit{dataloader}. \\ \hline
        Kartu Grafis (GPU) & NVIDIA GeForce GTX 1050 (4 GB VRAM) & Berperan dalam akselerasi komputasi tensor selama pelatihan model. \\ \hline
        Memori (RAM) & 8 GB DDR4 & Menunjang alokasi data sementara dengan kecepatan transfer 2400 MHz. \\ \hline
        Penyimpanan & 1 TB HDD & Digunakan sebagai repositori penyimpanan dataset utama. \\ \hline
    \end{tabularx}
\end{table}

Selain perangkat keras, lingkungan perangkat lunak juga dikonfigurasi menggunakan pustaka (\textit{library}) standar industri untuk menjamin reliabilitas eksperimen pelatihan.
Implementasi dilakukan menggunakan bahasa pemrograman \textbf{Python} dengan kerangka kerja utama \textbf{PyTorch}.
Rincian lengkap \textit{library} yang digunakan beserta fungsinya ditampilkan pada Tabel \ref{tab:software_spec}.

\begin{table}[H]
    \centering
    \caption{Daftar Perangkat Lunak dan Pustaka Pendukung}
    \label{tab:software_spec}
    \small
    \begin{tabularx}{\textwidth}{|l|X|} 
        \hline
        \textbf{Perangkat Lunak} & \textbf{Fungsi Utama} \\ \hline
        Python & Bahasa pemrograman dasar untuk seluruh implementasi teknis penelitian. \\ \hline
        PyTorch & Kerangka kerja utama untuk pembangunan, pelatihan, dan evaluasi model \textit{Deep Learning}. \\ \hline
        NumPy & Pustaka komputasi numerik untuk manipulasi matriks dan array. \\ \hline
        Scikit-learn & Pustaka untuk perhitungan metrik evaluasi (\textit{F1-Score}) dan \textit{Confusion Matrix}. \\ \hline
        Matplotlib \& Seaborn & Pustaka visualisasi data untuk pembuatan grafik hasil pelatihan. \\ \hline
        Weights \& Biases & Platform pemantauan (\textit{monitoring}) metrik pelatihan secara \textit{real-time}. \\ \hline
    \end{tabularx}
\end{table}

Guna memastikan eksperimen dapat direproduksi ulang (\textit{reproducible}) pada aspek logika program, dilakukan penguncian benih acak (\textit{Random Seed}) bernilai tetap (42) pada tiga komponen pustaka utama, yaitu:
\begin{enumerate}[noitemsep]
    \item \textbf{Python Native Random} \\
    Mengunci pengacakan pada operasi dasar.
    \item \textbf{NumPy} \\
    Menjamin konsistensi pada operasi manipulasi matriks dan pembagian data (\textit{fold splitting}).
    \item \textbf{PyTorch (CPU \& CUDA)} \\
    Mengunci inisialisasi bobot awal jaringan saraf agar start pelatihan selalu sama.
\end{enumerate}

Meskipun inisialisasi bobot dan pembagian data telah dikunci secara deterministik, konfigurasi \texttt{cudnn.deterministic} pada \textit{backend} GPU tetap dinonaktifkan (\textit{False}).
Keputusan ini diambil untuk memprioritaskan efisiensi sumber daya dan kecepatan komputasi, mengingat penegakan determinisme penuh pada operasi konvolusi GPU dapat meningkatkan waktu pelatihan secara signifikan.
Variasi hasil numerik mikroskopis yang mungkin timbul akibat optimasi perangkat keras ini dinilai dapat diabaikan (\textit{negligible}) dan tidak mempengaruhi validitas tren performa model secara keseluruhan. \par

\subsection{Penanganan Ketidakseimbangan Data (\textit{Weight Penalty})}
Meskipun dataset UrbanSound8K memiliki distribusi data yang relatif terstruktur, proses seleksi kelas dan penyusunan ulang \textit{fold} berpotensi menghasilkan ketidakseimbangan jumlah sampel antar kelas.
Ketidakseimbangan ini dapat memicu bias pada model, di mana model akan cenderung memprediksi kelas mayoritas (jumlah sampel banyak) dan mengabaikan kelas minoritas karena kontribusinya terhadap nilai \textit{loss} yang kecil. \par

Untuk memitigasi risiko tersebut, diterapkan strategi \textit{Weight Penalty} atau pemberian bobot penalti pada fungsi kerugian (\textit{Loss Function}).
Strategi ini bekerja dengan memberikan bobot \textit{loss} yang besar pada kelas dengan jumlah sampel sedikit, dan sebaliknya. 
Hal ini memaksa model untuk memberikan perhatian yang setara pada semua kelas selama proses pembaruan gradien tanpa memperhitungkan jumlah sampelnya.

Bobot penalti ($W_j$) untuk setiap kelas ke-$j$ dihitung secara otomatis sebelum pelatihan dimulai menggunakan formulasi berikut:

\begin{equation}
    W_j = \frac{N}{C \times N_j}
    \label{eq:class_weight}
\end{equation}

\noindent Keterangan:
\begin{itemize}
    \item $W_j$ : Bobot skalar yang dihasilkan untuk kelas $j$.
    \item $N$ : Total jumlah sampel dalam seluruh dataset latih.
    \item $C$ : Jumlah kelas total (4 kelas).
    \item $N_j$ : Jumlah sampel spesifik pada kelas $j$.
\end{itemize}
\medskip

Sebagai ilustrasi, jika kelas \textit{gun\_shot} memiliki jumlah sampel yang jauh lebih sedikit dibandingkan \textit{car\_horn}, maka nilai $N_j$ yang kecil pada penyebut akan menghasilkan nilai $W_j$ yang besar.
Nilai bobot ini kemudian diaplikasikan sebagai argumen parameter pada fungsi \textit{Cross Entropy Loss}.
Secara matematis, jika model melakukan kesalahan prediksi pada kelas \textit{gun\_shot}, nilai \textit{loss} akan dikalikan dengan faktor $W_j$ yang besar tersebut. Dengan begitu, model akan dihukum lebih berat dan dipaksa untuk belajar mengenali fitur kelas minoritas tersebut.

\subsection{Konfigurasi \textit{Optimizer} dan \textit{Scheduler}}
Proses pembaruan bobot model (\textit{weight update}) dilakukan menggunakan algoritma optimasi \textit{optimizer} \textbf{AdamW} (\textit{Adam with Weight Decay}).
Pemilihan AdamW didasari oleh kemampuannya dalam memisahkan mekanisme pembaruan bobot dengan \textit{weight decay}, sehingga lebih efektif dalam mencegah \textit{overfitting} dibandingkan algoritma Adam standar.
Pelatihan dilakukan dalam \textit{batch size} sebesar 8 selama maksimal 50 \textit{epoch}, dengan pengaturan \textit{Learning Rate} awal sebesar 5e-4 dan nilai \textit{Weight Decay} sebesar 1e-4.

Untuk mengoptimalkan proses adaptasi pelatihan model, diterapkan pula penyesuaian laju pembelajaran dinamis menggunakan \textit{scheduler} \textbf{\textit{ReduceLROnPlateau}}.
Mekanisme ini dirancang untuk memantau metrik \textit{Validation Loss}.
Apabila nilai kerugian validasi tersebut tidak mengalami penurunan selama 3 \textit{epoch} berturut-turut (\textit{patience}), maka nilai \textit{Learning Rate} akan direduksi secara otomatis sebesar setengah dari nilai sebelumnya (faktor 0,5).
Strategi ini membantu model untuk menemukan detail kecil global dengan lebih presisi (konvergensi) saat mendekati akhir pelatihan.

\subsection{Strategi Optimasi: \textit{Early Stopping} dan \textit{Checkpoint}}
Mengingat pelatihan dilakukan pada dataset terbatas, risiko \textit{overfitting} pada \textit{epoch} lanjutan menjadi sangat tinggi. Untuk mencegah hal tersebut, diterapkan dua mekanisme pencegahan otomatis:
\begin{enumerate}
    \item \textbf{\textit{Early Stopping}} \\
    Pelatihan model akan dihentikan secara paksa lebih awal apabila metrik evaluasi tidak mencatatkan rekor performa baru selama 5 \textit{epoch} berturut-turut. Ini mencegah model menghafal data latih secara berlebihan.
    \item \textbf{\textit{Model Checkpointing}} \\
    Selama proses pelatihan berjalan, sistem secara dinamis hanya akan menyimpan (\textit{save}) parameter bobot model pada \textit{epoch} yang berhasil mencetak nilai \textit{F1-Score} validasi tertinggi (\textit{best model}). Jika performa pada \textit{epoch} selanjutnya memburuk, model tidak akan disimpan, sehingga hasil akhir yang dievaluasi dipastikan adalah versi model yang paling optimal.
\end{enumerate}

\subsection{Pemantauan dan Pencatatan Eksperimen}
Dalam memantau pergerakan metrik evaluasi pelatihan (termasuk \textit{Train/Validation Loss}, \textit{F1-Score}, dan pergerakan \textit{Learning Rate}), metrik tersebut direkam dan divisualisasikan secara \textit{real-time} menggunakan alat bantu berupa \textit{dashboard} \textbf{Weights \& Biases (WandB)}.
Penggunaan alat ini memastikan transparansi rekam jejak pelatihan model.
Di akhir setiap pengujian \textit{fold}, sistem juga secara otomatis menggenerasi laporan grafik riwayat pelatihan dengan menampilkan metrik yang dijadikan bahan evaluasi.

\subsection{Konfigurasi Parameter Pelatihan} \label{sec:konfigurasi_eksperimen}
Rincian skenario pelatihan tadi telah membawa beberapa hyperparameter yang akan dijadikan sebagai tolak ukur eksperimen pada training model.
Hyperparameter yang dikendalikan dalam eksperimen ini disajikan pada Tabel \ref{tab:parameter_latih}.
Nilai-nilai yang ditetapkan dalam tabel ini ditetapkan berdasarkan studi literatur dan eksperimen awal untuk mendapatkan konvergensi yang optimal.\par

\begin{table}[H]
\centering
\caption{Parameter Konfigurasi Pelatihan}
\label{tab:parameter_latih}
\renewcommand{\arraystretch}{1.3} % Sedikit lebih renggang biar rapi
\begin{tabular}{|l|l|}
\hline
\textbf{Kategori} & \textbf{Konfigurasi / Nilai} \\ \hline
\multicolumn{2}{|c|}{\textbf{Hyperparameter Training}} \\ \hline
Batch Size & 8 \\ \hline
\textit{Epoch} & 50 \\ \hline
Num Workers & 2 \\ \hline
Learning Rate Awal & 0.0005 ($5e^{-4}$) \\ \hline
\multicolumn{2}{|c|}{\textbf{Optimizer}} \\ \hline
Tipe & AdamW \\ \hline
Weight Decay & 0.0001 ($1e^{-4}$) \\ \hline
\multicolumn{2}{|c|}{\textbf{Learning Rate Scheduler}} \\ \hline
Tipe & ReduceLROnPlateau \\ \hline
Faktor Pengurangan & 0.5 \\ \hline
Patience & 3 \\ \hline
Target Metrik & Validation Loss \\ \hline
\multicolumn{2}{|c|}{\textbf{Early Stopping}} \\ \hline
Patience & 5 \\ \hline
Target Metrik & Validation F1-Score \textless= Best Validation F1-Score \\ \hline
\multicolumn{2}{|c|}{\textbf{Reproducibilitas}} \\ \hline
Random Seed & 42 \\ \hline
\end{tabular}
\end{table}

\section{Analisis dan Evaluasi} \label{sec:evaluasi}
Setelah proses pelatihan selesai, kinerja model diukur menggunakan empat indikator utama:

\begin{enumerate}
    \item \textbf{\textit{F1-Score}} \\
    Digunakan sebagai metrik utama untuk mengukur akurasi dan sensitivitas model secara harmonis, memastikan semua kelas bahaya terdeteksi dengan baik.
    \item \textbf{Nilai \textit{Loss}} \\
    Digunakan untuk memantau proses konvergensi model selama pelatihan dan mendeteksi indikasi \textit{overfitting} atau \textit{underfitting}.
    \item \textbf{\textit{Confusion Matrix}} \\ 
    Digunakan untuk melihat detail distribusi prediksi benar dan salah pada setiap kelas spesifik.
\end{enumerate}
