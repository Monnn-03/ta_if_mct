\newpage
\chapter{METODE PENELITIAN} \label{Bab III}

\section{Alur Penelitian} \label{III.Alur}
Penelitian ini dilaksanakan melalui serangkaian tahapan sistematis guna memastikan model klasifikasi suara yang dikembangkan dapat bekerja optimal pada domain keselamatan penyandang tunarungu. Diagram alur penelitian ditunjukkan pada Gambar \ref{fig:alur_penelitian}.

\begin{figure}[H]
    \centering
    % Ganti 'gambar/alur_penelitian.png' dengan nama file gambar kamu
    \includegraphics[width=1.0\textwidth]{figure/Flowchart_TA.pdf} 
    \caption{Diagram Alur Penelitian}
    \label{fig:alur_penelitian}
\end{figure}

Penjelasan rinci mengenai tahapan penelitian adalah sebagai berikut:

\begin{enumerate}
    \item \textbf{Identifikasi Domain Penelitian} \\
    Tahap awal dilakukan dengan mencari referensi domain penelitian untuk klasifikasi suara. Berdasarkan pertimbangan ketersediaan dataset dan urgensi model klasifikasi, domain yang dipilih adalah domain keselamatan publik yang difokuskan untuk alat bantu penyandang tunarungu.

    \item \textbf{Studi Literatur} \\
    Dilakukan kajian literatur mendalam untuk menemukan urgensi penelitian, khususnya mengenai kebutuhan teknologi asistif yang mampu mengurangi risiko kecelakaan bagi penyandang tunarungu melalui pengenalan sinyal bahaya.

    \item \textbf{Identifikasi dan Akuisisi Dataset} \\
    Akuisisi dataset dilakukan dengan mengambil dataset sekunder yang sudah terstandarisasi, yaitu UrbanSound8K. Akuisisi dataset primer tidak dilakukan demi menghindari \textit{device bias} akibat perekaman dataset dengan perangkat non-standar (seperti smartphone) serta kendala regulasi keamanan pada perekaman kelas \textit{gun\_shot}. Maka dari itu, dataset sekunder terstandarisasi menjadi solusi yang valid dalam penelitian ini. Dari dataset tersebut, dilakukan seleksi kelas sinyal bahaya dengan strategi antisipasi terhadap kendala ketidakseimbangan data (\textit{imbalanced data}) yang telah disiapkan sejak awal.    

    \item \textbf{Pemilihan Model \textit{Pre-trained}} \\
    Mengingat keterbatasan data berisiko menyebabkan kegagalan pelatihan \textit{from scratch}, digunakan pendekatan \textit{Transfer Learning} memanfaatkan model \textit{Pre-trained}. Arsitektur PANNs (\textit{Pre-trained Audio Neural Networks}) dipilih karena telah dilatih pada dataset masif dan memiliki performa yang teruji.

    \item \textbf{Studi Dokumentasi Teknis} \\
    Tahap ini mempelajari karakteristik dataset dan model yang digunakan.
    Fokus utama dalam tahap ini adalah memahami mekanisme pembagian data (fold) pada dataset guna mencegah kebocoran data (\textit{data leakage}) dan mempelajari variasi representasi input pada arsitektur PANNs untuk menentukan skenario komparasi yang tepat.

    \item \textbf{Pra-pemrosesan Dataset (\textit{Pre-processing})} \\
    Serangkaian proses dilakukan untuk mengubah data mentah menjadi format yang siap latih, meliputi penanganan struktur \textit{fold}, seleksi kelas, dan penyesuaian format audio, serta penerapan teknik augmentasi temporal berupa \textit{random cropping} untuk menstandarisasi durasi input.

    \item \textbf{Penyesuaian Konfigurasi Model} \\
    Dilakukan modifikasi pada arsitektur model agar sesuai dengan tujuan klasifikasi 4 kelas bahaya, serta penerapan strategi untuk menangani ketidakseimbangan data.

    \item \textbf{Uji Coba \textit{Transfer Learning}} \\
    Tahapan inti di mana model dilatih untuk mengenali karakteristik suara spesifik. Proses ini melibatkan eksperimen \textit{Trial and Error} untuk menemukan konfigurasi parameter pelatihan yang paling optimal.

    \item \textbf{Evaluasi dan Analisis Hasil} \\
    Performa model hasil \textit{Fine-tuning} dievaluasi menggunakan metrik \textit{Confusion Matrix}, \textit{F1-Score}, serta analisis grafik \textit{Loss-Accuracy} dan waktu komputasi. Output model diuji validitasnya untuk memastikan kelayakan implementasi.

    \item \textbf{Kesimpulan} \\
    Berdasarkan hasil evaluasi, dilakukan perbandingan komparatif untuk menyimpulkan model mana yang memiliki performa paling unggul dan stabil.
\end{enumerate}

\section{Pengumpulan dan Pra-pemrosesan Data} \label{III.Preprocessing}
Sumber data utama dalam penelitian ini adalah dataset publik \textbf{UrbanSound8K}.
Dataset diunduh secara manual dari repositori Kaggle dalam format terkompresi (\texttt{.zip}).
Setelah diekstraksi, struktur dataset terdiri dari 10 folder (masing-masing mewakili satu \textit{fold}) beserta satu file metadata (\texttt{.csv}) yang memuat informasi nama file audio, \textit{class ID}, dan \textit{fold} asal. \par

Namun, dataset mentah ini memerlukan serangkaian penyesuaian agar relevan dengan konteks keselamatan penyandang tunarungu. 
Mengingat dataset ini awalnya berisi 10 kelas suara umum di perkotaan yang tersebar dalam 10 \textit{fold}, penelitian ini memfokuskan pada seleksi kelas bahaya spesifik serta menyusun ulang data menjadi 5 fold eksperimen.
Sebagai langkah antisipasi terhadap keterbatasan data setelah seleksi kelas, strategi augmentasi temporal diterapkan untuk memperkaya variasi data latih.
Oleh karena itu, tahap pra-pemrosesan data menjamin integritas data dan mencegah kebocoran informasi (\textit{data leakage}) selama proses pelatihan, sebagaimana dijabarkan pada tahapan berikut.\par

\subsection{Strategi Penyusunan Ulang Data (\textit{Fold Mapping})}
Dataset UrbanSound8K secara bawaan terbagi ke dalam 10 \textit{fold}. Untuk efisiensi eksperimen tanpa melanggar aturan independensi data, penelitian ini menyusun ulang 10 \textit{fold} tersebut menjadi 5 \textit{fold} eksperimen baru. Penyusunan ini dilakukan secara berurutan (misalnya Fold 1 dan 2 menjadi Fold Baru 1) tanpa pengacakan data antar \textit{fold}.
% Gambar
\begin{figure}[H]
    \centering
    % Ganti 'gambar/alur_penelitian.png' dengan nama file gambar kamu
    \includegraphics[width=1.0\textwidth]{figure/Fold_Map.pdf} 
    \caption{Ilustrasi Strategi Penyusunan Ulang Fold pada Dataset UrbanSound8K}
    \label{fig:strategi_fold_mapping}
\end{figure}

Adapun penyusunan ini didasari oleh dua pertimbangan, yaitu rasio pembagian data yang ideal dan efisiensi sumber daya komputasi. Skema 5-\textit{fold} menghasilkan proporsi 80\% data latih dan 20\% data uji. Proporsi ini memberikan model evaluasi yang lebih representatif terhadap variasi data daripada skema 10-\textit{fold} bawaan yang menyisakan 10\% data uji. Selain memberikan porsi data yang ideal, skema tersebut berdampak mengurangi waktu komputasi pelatihan model tanpa mengurangi validitas pengujian.

Dikarenakan skema baru tersebut, maka mekanisme validasi yang digunakan selanjutnya pada model adalah \textit{5-fold cross validation}. Pada iterasi setiap pengujiannya, satu \textit{fold} dialokasikan sebagai data uji secara bergantian dan empat \textit{fold} sisanya akan digunakan sebagai data latih model. Mekanisme rotasi ini diterapkan agar model selalu diuji dengan data yang berbeda dari yang sudah pernah dipelajari saat proses latih, sehingga hasil evaluasi mencerminkan kemampuan generalisasi yang sebenarnya.

\subsection{Seleksi Kelas (\textit{Class Filtering})}
Tidak seluruh kelas pada dataset UrbanSound8K relevan dengan konteks keselamatan tunarungu. Oleh karena itu, dilakukan penyaringan untuk hanya mengambil 4 kelas prioritas yang merepresentasikan sinyal bahaya, yaitu:
\begin{enumerate}
    \item \textbf{\textit{gun\_shot} (Tembakan)} \newline
    Suara tembakan senjata api merupakan sinyal bahaya dengan tingkat fatalitas yang sangat tinggi. Walaupun kejadiannya jarang terjadi, khususnya di Indonesia, deteksi suara ini menjadi langkah mitigasi risiko yang baik dalam melindungi penyandang tunarungu.
    
    \item \textbf{\textit{siren} (Sirine)} \newline
    Suara sirine menandakan keberadaan kendaraan prioritas (ambulans, pemadam kebakaran, atau patroli polisi) yang sering kali melaju dengan kecepatan tinggi dan memiliki hak prioritas jalan. Dengan deteksi suara tersebut, pengguna dapat mengambil langkah untuk segera menepi dan menghindari jalur lintasan kendaraan tersebut.
    
    \item \textbf{\textit{dog\_bark} (Gonggongan Anjing)} \newline
    Suara anjing yang menggonggong berpotensi menjadi sinyal bahaya, terutama jika anjing tersebut berupa anjing liar yang dapat menyerang secara tiba-tiba. Dengan mendeteksi suara ini, pengguna dapat langsung mengetahui di mana posisi anjing tersebut dan mengambil langkah untuk antisipasi ancaman.
    
    \item \textbf{\textit{car\_horn} (Klakson Mobil)} \newline
    Suara klakson mobil menjadi sinyal penting pada lalu lintas, yang salah satu fungsinya adalah sebagai peringatan dari pengemudi kendaraan tersebut kepada pejalan kaki yang berada di jalur lintasnya. Dengan deteksi ini, pengguna dapat lebih waspada terhadap situasi lalu lintas di sekitarnya.
\end{enumerate}

\subsection{Augmentasi Temporal (\textit{Random Cropping})}
Seleksi kelas bahaya yang telah dilakukan menghasilkan jumlah data yang relatif sedikit pada kelas yang terpilih, yang berpotensi membuat model kekurangan data untuk latih dan uji. 
Oleh karena itu, teknik augmentasi hadir sebagai solusi untuk memperkaya variasi data tanpa perlu menambah jumlah sampel dengan dataset lain.
Teknik ini juga mempersingkat waktu dan sumber daya komputasi dikarenakan model hanya mempelajari sebagian fitur penting dari seluruh bagian fitur pada data aslinya.\par

Sebelum melakukan proses augmentasi, durasi audio akan diperiksa terlebih dahulu apakah sesuai dengan standar yang telah ditetapkan, yaitu 5 detik. 
Durasi 5 detik ini dipilih karena dataset UrbanSound8K memiliki data audio yang berdurasi rata-rata 4 detik, sehingga 5 detik merupakan durasi yang cukup aman untuk dijadikan standar dalam penelitian ini.
Jika audio asli berdurasi kurang dari 5 detik, maka audio akan ditambahkan \textit{padding} hingga durasinya mencapai 5 detik.
Jika audio asli berdurasi lebih dari 5 detik, maka audio akan dipotong hingga berdurasi 5 detik.
Setelah standarisasi durasi selesai, maka data siap untuk diproses menggunakan teknik augmentasi. \par

Teknik augmentasi yang diterapkan adalah \textit{Random Cropping}, yaitu pemotongan acak pada segmen audio sepanjang durasi tertentu.
Pada setiap \textit{epoch} pelatihan, segmen 1 detik akan diambil secara acak dari durasi 5 detik tersebut. Ini memberikan variasi temporal pada model untuk belajar mengenali karakteristik suara yang berbeda dari berbagai posisi dalam rekaman asli pada setiap \textit{epoch}.
Teknik \textit{Random Cropping} ini tidak diterapkan pada data uji dikarenakan berpotensi mengubah distribusi data uji, sehingga model tidak dapat mencapai nilai evaluasi secara maksimal. \par

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figure/Random_Crop.pdf} 
    \caption{Ilustrasi Teknik \textit{Random Cropping} Pada Setiap \textit{Epoch}}
    \label{fig:random_cropping}
\end{figure}

\section{Konfigurasi Model} \label{sec:konfigurasi_model}
% Kasih paragraf pembuka
Model yang digunakan dalam penelitian ini adalah model PANNs dengan 3 arsitektur berbeda, yaitu \textit{Res1dNet31}, \textit{ResNet38}, dan \textit{Wavegram-Logmel-CNN}.
Ketiga arsitektur ini telah terbukti memiliki performa yang baik pada tugas klasifikasi audio berdasarkan masing-masing representasi inputnya. 
Namun, agar model dapat berfungsi optimal sesuai dengan konteks klasifikasi 4 kelas bahaya pada dataset UrbanSound8K, diperlukan beberapa penyesuaian konfigurasi model, yaitu sebagai berikut. \par

\subsection{Adaptasi Arsitektur (\textit{Transfer Learning})}
Penyesuaian arsitektur dilakukan pada lapisan keluaran (\textit{output layer}) dan mekanisme pembekuan bobot (\textit{Freeze Base}). 
Jumlah \textit{neuron} pada lapisan akhir disesuaikan dari 527 \textit{node} menjadi 4 \textit{node} (sesuai jumlah kelas pilihan). 
Pada model asli PANNs, lapisan akhir menggunakan fungsi aktivasi \textit{sigmoid} yang mengeluarkan output berupa probabilitas tiap kelasnya sendiri.
Tentu saja, lapisan tersebut cocok dalam konteks klasifikasi \textit{Multi-Label}. 
Akan tetapi, klasifikasi model yang ditentukan pada penelitian ini adalah klasifikasi \textit{Single-Label}, sehingga fungsi tersebut diganti menjadi lapisan \textit{Linear} (Logits) yang memilih satu kelas dengan probabilitas paling tinggi daripada kelas lainnya. \par

Mengingat penelitian ini menggunakan metode \textit{Transfer Learning}, lapisan dasar fitur (\textit{base model}) pada model PANNs dibekukan agar model tidak menghapus ingatan fitur dasar yang telah dipelajari dari dataset besar sebelumnya (AudioSet). 
Strategi ini memastikan model memiliki inisialisasi bobot yang baik dan hanya perlu mempelajari pola baru yang spesifik pada dataset target. \par

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figure/Transfer_Learning.pdf} 
    \caption{Ilustrasi \textit{Transfer Learning} (\textit{Freeze} vs \textit{Trainable Base})}
    \label{fig:transfer_learning}
\end{figure}


\subsection{Penanganan Ketidakseimbangan Data (\textit{Weight Penalty})}
Untuk mengatasi distribusi data yang tidak seimbang antar kelas, diterapkan mekanisme \textit{Weight Penalty} pada fungsi kerugian (\textit{Loss Function}). Metode ini bekerja dengan memberikan bobot penalti yang lebih besar ketika model salah memprediksi kelas minoritas (jumlah sampel sedikit). Hal ini memaksa model untuk memberikan perhatian yang setara pada semua kelas, mencegah bias prediksi ke arah kelas mayoritas.

\section{Konfigurasi Parameter Eksperimen} \label{sec:konfigurasi_eksperimen}

Penelitian ini menggunakan model \textit{Pre-trained Audio Neural Networks} (PANNs) sebagai kerangka dasar (\textit{backbone}). Model ini telah dilatih sebelumnya (\textit{pre-trained}) menggunakan dataset AudioSet yang berskala besar. Untuk mengadaptasi model tersebut ke dalam kasus klasifikasi 4 kelas pada dataset UrbanSound8K, dilakukan metode \textit{Transfer Learning} dengan membekukan (\textit{freeze}) lapisan ekstraksi fitur awal dan hanya melakukan \textit{fine-tuning} pada lapisan \textit{Fully Connected} (FC) terakhir.

Agar hasil evaluasi antar model (\textit{ResNet38}, \textit{Res1dNet31}, dan \textit{Wavegram-Logmel-CNN}) dapat diperbandingkan secara adil (\textit{apple-to-apple}), seluruh proses pelatihan menggunakan konfigurasi \textit{hyperparameter} yang seragam. Rincian parameter konfigurasi yang dikendalikan dalam eksperimen ini disajikan pada Tabel \ref{tab:parameter_latih}.

\begin{table}[H]
\centering
\caption{Parameter Konfigurasi Pelatihan}
\label{tab:parameter_latih}
\renewcommand{\arraystretch}{1.3} % Sedikit lebih renggang biar rapi
\begin{tabular}{|l|l|}
\hline
\textbf{Kategori} & \textbf{Konfigurasi / Nilai} \\ \hline
\multicolumn{2}{|c|}{\textbf{Preprocessing Data}} \\ \hline
Input Sampling Rate & 32.000 Hz \\ \hline
Input Duration & 5 Detik (160.000 samples) \\ \hline
Teknik Augmentasi & \textit{Random Cropping} \& \textit{Zero-padding} \\ \hline
Skema Validasi & 5-Fold Cross Validation (Group Split) \\ \hline
\multicolumn{2}{|c|}{\textbf{Hyperparameter Training}} \\ \hline
Batch Size & 8 \\ \hline
\textit{Epoch} & 15 \\ \hline
Optimizer & Adam \\ \hline
Learning Rate & 0.001 ($1e^{-3}$) \\ \hline
Loss Function & Cross Entropy dengan \textit{Class Weights} \\ \hline
\multicolumn{2}{|c|}{\textbf{Reproducibilitas}} \\ \hline
Random Seed & 42 \\ \hline
Perangkat Keras & GPU NVIDIA GeForce GTX 1050 \\ \hline
\end{tabular}
\end{table}

\section{Analisis dan Evaluasi} \label{sec:evaluasi}
Setelah proses pelatihan selesai, kinerja model diukur menggunakan empat indikator utama:

\begin{enumerate}
    \item \textbf{Confusion Matrix:} Digunakan untuk melihat detail distribusi prediksi benar dan salah pada setiap kelas spesifik.
    \item \textbf{F1-Score:} Digunakan sebagai metrik utama untuk mengukur presisi dan sensitivitas model secara harmonis, memastikan semua kelas bahaya terdeteksi dengan baik.
    \item \textbf{Grafik Loss \& Accuracy:} Digunakan untuk memantau proses konvergensi model selama pelatihan dan mendeteksi indikasi \textit{overfitting} atau \textit{underfitting}.
    \item \textbf{Waktu Training:} Digunakan sebagai acuan efisiensi komputasi model.
\end{enumerate}
